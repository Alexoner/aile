Motif detection using a Hidden Markov Model
===========================================

Introduction
------------

This notes started as an adaptation of `Rabiner's tutorial
<http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.2084>`_ to
Profile HMM.


Problem description
-------------------
We have a sequence of length :math:`n` over some alphabet
:math:`\pmb{A}`. This sequence is generated by a random process, so the 
sequence is a random variable :math:`\pmb{X}`:

.. math::

   \pmb{X} = X_1X_2...X_n

As said before the range of each :math:`X_i` is the alphabet:

.. math::

   Val(X_i) = \pmb{A}

We will call each element of :math:`\pmb{A}` a symbol. 
The size of the alphabet is :math:`|\pmb{A}|`. 

We assume that each :math:`X_i` can be part either of some repeating
motif of length :math:`W` or be just background noise. When
considering repeating motifs we allow to be gaps and deletions on the
motif. For example consider the following sequences made of the
letters A,B,C,D,E (spaces added to aid the reader):

- Repeating motif 

  ``ABCDE ABCDE ABCDE ABCDE ABCDE``

- With some baground noise between motif repetitions

  ``ABCDE AB ABCDE BB ABCDE C ABCDE CCCC ABCDE``

- With deletions

  ``ABDE AB ABCDE BB BCDE C ABCDE CCCC ABDE``

- With gaps

  ``ABAACDE ABCDE A ACCCBCDE C ABCDE ABCE``


Model
-----

To account for background noise, deletions and gaps we model the
generation of the sequence with a `Profile Hidden Markov Model
<http://bioinformatics.oxfordjournals.org/content/14/9/755.full.pdf+html>`_
(PHMM). In a PHMM the hidden process generating the sequence changes
between states according to the following state diagram, where each node
represents an state and the process jumps randomly from one state to
another state following the arrows:

.. only:: html

   .. figure:: _static/PHMM_1.svg
      :align: center

.. only:: latex

   .. figure:: _static/PHMM_1.pdf
      :align: center

There are three types of states:

- Background states 

  .. math::

     \pmb{S}^B=\left\{b_1,...,b_W\right\}
 
- Motif states 

  .. math:: 

     \pmb{S}^M=\left\{m_1,...,m_W\right\}


- Delete states 

  .. math::

     \pmb{S}^D=\left\{d_1,...,d_W\right\}


When the process jumps to a background state it emits a letter of the
sequence according to the background distribution. We assume that all
background states follow the same categorical distribution where each
symbol :math:`a \in \pmb{A}` is emitted with probability :math:`f^B_a`.

When the process jumps to a motif state it emits a letter of the
sequence according to the motif distribution. We assume that the
emission probability depends on which motif state we are in, and so if
we are in state :math:`m_j` each symbol :math:`a` is emitted with
probability :math:`f^M_{ja}`.

When the process jumps to a deletion state it emits nothing. These are
silent states introduced only for the purpose of allowing jumps
between motifs :math:`m_j` and :math:`m_k` for :math:`k>j+1`.

Notice that the state diagram has loops. This is because it models the motif,
which is allowed to repeat.

The above diagram is incomplete if we don't specify the probabilites of
state transitions. The following table gives them for direct transitions
between states:

+------------+------------+---------------------------------------------------------------+
|                         | To state                                                      |
|                         +------------+----------------+----------------+----------------+
|                         | :math:`b_j`| :math:`b_{j+1}`| :math:`m_{j+1}`| :math:`d_{j+1}`|
+------------+------------+------------+----------------+----------------+----------------+
|            | :math:`b_j`| b          | 0              | 1 - b          | 0              |
|            +------------+------------+----------------+----------------+----------------+
| From state | :math:`m_j`| 0          | :math:`m_b`    | :math:`m`      | :math:`m_d`    |
|            +------------+------------+----------------+----------------+----------------+
|            | :math:`d_j`| 0          | 0              | 1 - d          | d              |
+------------+------------+------------+----------------+----------------+----------------+


To avoid introducing too much parameters we have assumed that the
transition probabilities are stationary.

Now let's define the random variable :math:`Z_i` as the state of the
process when emitting symbol :math:`X_i`. Then the range of :math:`Z_i` is:

.. math::

   \pmb{S} = Val(Z_i) = \pmb{S}^B \cup \pmb{S}^M

With these variables we have the familiar HMM. Notice that although
similar to the graph of the PHMM this one has different meaning. The
former was an state diagram and this one is a Bayesian network. Each
node is now a random variable instead of a concrete state:

.. only:: html

   .. figure:: _static/HMM_1.svg
      :align: center
      :figwidth: 60 %

.. only:: latex

   .. figure:: _static/HMM_1.pdf
      :align: center
      :figwidth: 60 %

We are capable of computing the transition probabilities between the
emitting states :math:`Z_i`. For this we must consider any possible path that
connects the two states, compute the probability of each path and sum
all the probabilities. To make this more concrete consider the case of
motif width :math:`W=6`, where we start from state :math:`m_2`:

.. only:: html

   .. figure:: _static/PHMM_2.svg
      :align: center

.. only:: latex

   .. figure:: _static/PHMM_2.pdf
      :align: center

We can see the pattern in the above formulas. If we consider the path going
from :math:`m_j` to :math:`m_k` the number of delete states we must
cross is:

.. math::

   L_{jk} = (k - j - 2) \mod W
   
Then the probability of the path is:

.. math::

   m_dd^{L_{jk}}(1-d) + [k=j+1]m

Where :math:`[k=j+1]` is the `Iverson bracket
<https://en.wikipedia.org/wiki/Iverson_bracket>`_, which takes the
value 1 only when the condition inside the brackets is true, and zero
otherwise.

Notice that given the value of :math:`j` and :math:`L_{jk}` we can
recover :math:`k` as:

.. math::

   k = 1 + (j + L_{jk} + 1) \mod W

To compute the final probability we need to take into account the
cases where we make several loops over all the delete states. Each
loop has probability :math:`d^W`, and :math:`l` loops then
:math:`(d^W)^l`. The following figure shows the possible paths between
two states depending on the number of loops:

.. only:: html

   .. figure:: _static/PHMM_3.svg
      :align: center

.. only:: latex

   .. figure:: _static/PHMM_3.pdf
      :align: center

The final probability is then:

.. math::

   P\left(Z_{i+1}=m_k|Z_i=m_j\right) = m_dd^{L_{jk}}\left(\sum_{l=0}^\infty(d^W)^l\right)(1-d) + [k=j+1]m

Making the summation we get we get the final transition probabilities
when starting from state :math:`m_j`:

.. math::

   P\left(Z_{i+1}=b_{j+1}|Z_i=m_j\right) &= m_b \\
   P\left(Z_{i+1}=m_k|Z_i=m_j\right) &= m_dF(L_{jk}, d) + [k=j+1]m \\
   F(l, d) &= d^l\frac{1 - d}{1 - d^W}

The behavior of :math:`F(l, d)` near the boundaries is:

.. math::

   \underset{d \to 0}{\lim} F &= [l=0] \\
   \underset{d \to 1}{\lim} F &= 1/W

The following figure shows a plot for :math:`W=6`:

.. only:: html

   .. figure:: _static/F_jk.svg
      :align: center

.. only:: latex

   .. figure:: _static/F_jk.pdf
      :align: center

The transitions starting from a background states are trivial:

.. math::

   P\left(Z_{i+1}=b_j|Z_i=b_j\right) &= b \\
   P\left(Z_{i+1}=m_j|Z_i=b_j\right) &= 1 - b

The emission probabilities:

.. math::

   P\left(X_i=a|Z_i=b_j\right) &= f^B_a \\
   P\left(X_i=a|Z_i=m_j\right) &= f^M_{ja}


Parameter estimation
--------------------

Expectation-Maximization (EM)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For convenience let's aggregate all the model parameters into a single
vector:

.. math::

   \pmb{\theta} &= \left(\pmb{t}, \pmb{f}^B, \pmb{f}^M\right) \\
   \pmb{t} &= \left(b, \pmb{t}^M\right) \\
   \pmb{t}^M &= \left(d, m_d, m, m_b\right)

Using `EM
<https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm>`_
each step takes the form, where :math:`\pmb{\theta}^0`
and :math:`\pmb{\theta}^1` are the current and next estimates of the
parameters respectively:

.. math::

   \pmb{\theta}^1 &= \underset{\pmb{\theta}}{\arg\max}
   Q(\pmb{\theta}|\pmb{\theta}^0) \\
   Q(\pmb{\theta}|\pmb{\theta}^0) &= \log P(\pmb{\theta}) +
   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right]

:math:`\pmb{x}^D` is the training data, a particular realization of :math:`\pmb{X}`.

:math:`P(\pmb{\theta})` are the prior probabilities on the
parameters. We are going to consider priors only on :math:`\pmb{f}^M`.

EM on a HMM
~~~~~~~~~~~

Taking into account that in a HMM the joint probability distribution
factors as:

.. math::

   P(\pmb{X}, \pmb{Z}|\pmb{\theta}) = \prod_{i=1}^nP(Z_i|Z_{i-1}, \pmb{\theta})P(X_i|Z_i,
   \pmb{\theta})


We expand the expectation in the EM step as:

.. math::

   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right] = 
   \sum_{\pmb{z}}P(\pmb{z}|\pmb{x}^D,\pmb{\theta}^0)\sum_{i=1}^n
   \left[\log P(x^D_i|z_i, \pmb{\theta}) + \log P(z_i|z_{i-1}, \pmb{\theta})\right]

Interchanging the summations:

.. math::

   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right] = 
   \sum_{i=1}^n\sum_{\pmb{z}}P(\pmb{z}|X,\pmb{\theta}^0)
   \left[\log P(x^D_i|z_i, \pmb{\theta}) + \log P(z_i|z_{i-1}, \pmb{\theta})\right]

Defining the set :math:`\pmb{C}_i=\left\{Z_{i-1}, Z_i\right\}` we can always do:

.. math::

   P(\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0) = P(\pmb{Z} - \pmb{C}_i|\pmb{C}_i, \pmb{x}^D, \pmb{\theta}^0)P(\pmb{C}_i|\pmb{x}^D,\pmb{\theta}^0)

Now the summation over :math:`\pmb{Z}` can be decomposed as:

.. math::

   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right] = 
   \sum_{i=1}^n\left(\sum_{\pmb{z} - \pmb{c}_i}P(\pmb{z} - \pmb{c}_i|\pmb{x}^D,\pmb{\theta}^0)\right)
   \sum_{\pmb{c}_i}P(\pmb{c_i}|\pmb{x}^D, \pmb{\theta}^0)\left[\log P(x^D_i|z_i, \pmb{\theta}) + \log P(z_i|z_{i-1}, \pmb{\theta})\right]

Of course:

.. math::

   \sum_{\pmb{z} - \pmb{c}_i}P(\pmb{z} -
   \pmb{c}_i|\pmb{x}^D,\pmb{\theta}^0) = 1

And so we finally get:

.. math::

   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right] = 
   \sum_{i=1}^n
   \sum_{z_{i-1},z_i}P(z_{i-1},z_i|\pmb{x}^D, \pmb{\theta}^0)\left[\log P(x^D_i|z_i, \pmb{\theta}) + \log P(z_i|z_{i-1}, \pmb{\theta})\right]

Computing :math:`P(Z_{i-1}, Z_i|\pmb{X},\pmb{\theta})`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To unclutter a little let's call:

.. math::

   \xi_i(s_1, s_2) &= P(Z_{i-1}=s_1, Z_i=s_2|\pmb{x}^D, \pmb{\theta}^0) \\
   \gamma_i(s) &= P(Z_i=s|\pmb{x}^D, \pmb{\theta}^0)

Notice that:

.. math::

   \gamma_i(s) = \sum_{s_1} \xi_i(s_1, s)

And so we just need to compute :math:`\xi_i`. To compute it we first
apply Bayes theorem:

.. math::

   P(Z_{i-1}, Z_i|\pmb{X},\pmb{\theta}^0) =
   \frac{P(\pmb{X}|Z_{i-1},Z_i,\pmb{\theta}^0)P(Z_{i-1}, Z_i|\pmb{\theta}^0)}{P(\pmb{X}|\pmb{\theta}^0)}

Now, thanks to the Markov structure of the probabilities we can factor
things:

.. math::

   P(\pmb{X}|Z_{i-1},Z_i,\pmb{\theta}^0) &=
   P(X_1...X_{i-1}|Z_{i-1},\pmb{\theta}^0)P(X_i...X_n|Z_i,\pmb{\theta}^0)
   \\
   P(Z_{i-1},Z_i|\pmb{\theta}^0) &= P(Z_{i-1}|\pmb{\theta}^0)P(Z_i|Z_{i-1},\pmb{\theta}^0)
   
Renaming things a bit again:

.. math::

   \alpha_i(s) &= P(X_1...X_i,Z_i=s|\pmb{\theta}^0) \\
   \beta_i(s) &= P(X_i...X_n|Z_i=s,\pmb{\theta}^0)

We get that:

.. math::

   \tilde{\xi}_i(s_1, s_2) &=
   \alpha_{i-1}(s_1)\beta_i(s_2)P(Z_i=s_2|Z_{i-1}=s_1,\pmb{\theta}^0)
   \\
   \xi_i(s_1, s_2) &= \frac{\tilde{\xi}_i(s_1, s_2)}{\sum_{s_1,s_2}\tilde{\xi}_i(s_1, s_2)}

We compute the first values of :math:`\alpha` to see the pattern:

.. only:: html

   .. figure:: _static/forward.svg
      :align: center
      :figwidth: 60 %

.. only:: latex

   .. figure:: _static/forward.pdf
      :align: center
      :figwidth: 60 %

In general:

.. math::

   \alpha_1(s) &= P(Z_1=s)P(X_1|Z_1=s) \\
   \alpha_i(s_2) &=
   \left[\sum_{s_1}\alpha_{i-1}(s_1)P(Z_i=s_2|Z_{i-1}=s_1)\right]P(X_i|Z_i=s_2)


Following the same process but starting from the end of the HMM we
get:

.. math::

   \beta_n(s) &= P(X_n|Z_n=s) \\
   \beta_{i-1}(s_1) &= 
   \left[\sum_{s_2}\beta_i(s_2)P(Z_i=s_2|Z_{i-1}=s_1)\right]P(X_{i-1}|Z_{i-1}=s_1)
   
Re-estimation equations
~~~~~~~~~~~~~~~~~~~~~~~

We now separate the expectation in two independent parts:

.. math::

   E_{\pmb{Z}|\pmb{x}^D,\pmb{\theta}^0}\left[\log P(\pmb{x}^D,\pmb{Z}|\pmb{\theta})\right] &= 
   E^1(\pmb{f}^M, \pmb{f}^B) + E^2(\pmb{t}) \\
   E^1(\pmb{f}^M, \pmb{f}^B) &= \sum_{i=1}^n \sum_{s \in \pmb{S}}\gamma_i(s)\log P(x^D_i|s, \pmb{f}^M, \pmb{f}^B) \\
   E^2(\pmb{t}) &= \sum_{i=1}^n \sum_{s_1,s_2 \in \pmb{S}}\xi_i(s_1,s_2)\log P(s_2|s_1, \pmb{t})

We can continue splitting into independent parts:

.. math::

   E^1(\pmb{f}^M, \pmb{f}^B) &= E^{1B}(\pmb{f}^B) + E^{1M}(\pmb{f}^M) \\
   E^{1B}(\pmb{f}^B) &= \sum_{i=1}^n \sum_{s \in \pmb{S}^B}\gamma_i(s)\log P(x^D_i|s, \pmb{f}^B) \\
   E^{1M}(\pmb{f}^M) &= \sum_{i=1}^n \sum_{s \in \pmb{S}^M}\gamma_i(s)\log P(x^D_i|s, \pmb{f}^M)

And also:

.. math::

   E^2(\pmb{t}) &= E^{2B}(b) + E^{2M}(\pmb{t}^M) \\
   E^{2B}(b) &= \sum_{i=1}^n\sum_{s_1 \in \pmb{S}^B}\sum_{s_2 \in \pmb{S}}\xi_i(s_1,s_2)\log P(s_2|s_1, b) \\
   E^{2M}(\pmb{t}^M) &= \sum_{i=1}^n\sum_{s_1 \in \pmb{S}^M}\sum_{s_2 \in \pmb{S}}\xi_i(s_1,s_2)\log P(s_2|s_1, \pmb{t}^M)

 
We have now 4 independent maximization problems:

.. math::

   \left(\pmb{f}^B\right)^1 &= \underset{\pmb{f}^B}{\arg \max}E^{1B}\\
   \left(\pmb{f}^M\right)^1& = \underset{\pmb{f}^M}{\arg \max}\left\{\log P(\pmb{f}^M) + E^{1M}\right\} \\
   b^1 &= \underset{b}{\arg \max} E^{2B} \\
   \left(\pmb{t}^M\right)^1 &= \underset{\pmb{t}^M}{\arg \max} E^{2M}
   

Estimation of :math:`\pmb{f}^B`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We need to solve:

.. math::

   \left(\pmb{f}^B\right)^1 = \underset{\pmb{f}^B}{\arg \max}E^{1B}

With the constraint:

.. math::

   g_B &= \sum_{a \in \pmb{A}} f^B_a - 1 = 0 

We will enforce the constraints using `Lagrange multipliers
<https://en.wikipedia.org/wiki/Lagrange_multiplier>`_, and taking derivatives:

.. math::

   \frac{\partial}{\partial \pmb{f}^B,\lambda_B}\left\{E^{1B} - \lambda_Bg_B\right\} = 0

From this we get the closed form solution:

.. math::

   \tilde{f}^B_a &= \sum_{i=1}^n[x_i^D=a]\sum_{j=1}^W \gamma_i(b_j)  \\
   f^B_a &= \frac{\tilde{f}^B_a}{\sum_{a \in \pmb{A}}\tilde{f}^B_a}

Estimation of :math:`\pmb{f}^M`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We need to solve:

.. math::

   \left(\pmb{f}^M\right)^1& = \underset{\pmb{f}^M}{\arg \max}\left\{\log P(\pmb{f}^M) + E^{1M}\right\} 

With the constraint:

.. math::

   g_j &= \sum_{a \in \pmb{A}} f^M_{ja} - 1 = 0 

We will enforce the constraints using `Lagrange multipliers
<https://en.wikipedia.org/wiki/Lagrange_multiplier>`_, and taking derivatives:

.. math::

   \frac{\partial}{\partial \pmb{f}^B,\lambda_j}\left\{\log P(\pmb{f}^M) + E^{1M} - \lambda_jg_j\right\} = 0

If we use `Dirichlet distribution
<https://en.wikipedia.org/wiki/Dirichlet_distribution>`_ over the
symbols of each :math:`\pmb{f}^M_j`. The log-probability of the prior is
then:

.. math::

   \log P(\pmb{f}^M_j|\pmb{\varepsilon}) = -\log B(\pmb{\varepsilon}) + \sum_{s \in \pmb{A}}(\varepsilon_s - 1)\log
   \pmb{f}^M_j

And the derivative:

.. math::
   
   \frac{\partial}{\partial f^M_{ja}}\log P(\pmb{f}^M_j|\pmb{\varepsilon}) =
   \frac{\varepsilon_a - 1}{f^M_{ja}}

From this we get the closed form solution:

.. math::

   \tilde{f}^M_{ja} &= \sum_{i=1}^n[x_i^D=a]\sum_{j=1}^W \gamma_i(m_j) \\
   f^M_{ja} &=
   \frac{ \varepsilon_a - 1 + \tilde{f}^M_{ja}}{\varepsilon_0 - 1 +
   \sum_{a \in \pmb{A}}\tilde{f}^M_{ja}}

Where :math:`\varepsilon_0` is called the concentration parameter and it's:

.. math::

   \varepsilon_0 = \sum_{a \in \pmb{A}}\varepsilon_a


Estimation of :math:`b`
~~~~~~~~~~~~~~~~~~~~~~~

We need to solve:

.. math::

   b^1 = \underset{b}{\arg \max} E^{2B}

Taking derivatives we get:

.. math::

   b^1 = \frac{\sum_{i=1}^n\sum_{j=1}^W \xi_i(b_j, b_j)}{
   \sum_{i=1}^n\sum_{j=1}^W \xi_i(b_j, b_j) + 
   \sum_{i=1}^n\sum_{j=1}^W \xi_i(b_j, m_j)}

Estimation of :math:`\pmb{t}^M`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We need to solve:

.. math::

   \left(\pmb{t}^M\right)^1 &= \underset{\pmb{t}^M}{\arg \max} E^{2M}

Subject to the constraint:

.. math::

   g_m = m_b + m + m_d - 1 = 0

Trying to solve the above problem using Lagrange multipliers gives as
a result a set of highly non-linear equations in :math:`d`, and since
the rest of the parameters are coupled to :math:`d` either directly or
trough the constraint it is not possible to find a closed form
solution. Because of this we throw away the Lagrange multipliers and
solve the maximization problem numerically.

Let's recap the shape of our problem:

.. math::

   E^{2M}(\pmb{t}^M) &= \sum_{i=1}^n\sum_{s_1 \in \pmb{S}^M}\sum_{s_2
   \in \pmb{S}}\xi_i(s_1,s_2)\log P(s_2|s_1, \pmb{t}^M) \\

.. math::

   P\left(Z_i=b_{j+1}|Z_{i-1}=m_j\right) &= m_b \\
   P\left(Z_i=m_k|Z_{i-1}=m_j\right) &= m_dF(L_{jk}, d) + [k=j+1]m \\
   F(l, d) &= d^l\frac{1 - d}{1 - d^W} \\
   L_{jk} &= (k - j - 2) \mod W \\
   K_{jl} &= 1 + \left[(j + l + 1) \mod W\right]

We rewrite the summation as:

.. math::

   E^{2M}(\pmb{t}^M) &=  \sum_{i=1}^n\sum_{j=1}^W
       \left\{
          \xi_i(b_{j+1}, m_j)\log P(b_{j+1}|m_j, \pmb{t}^M) + 
          \sum_{l=0}^{W-1}\xi_i(m_j,m_{K_{jl}})\log P(m_{K_{jl}}|m_j,
          \pmb{t}^M)
       \right\} \\
                     &= \sum_{i=1}^n\sum_{j=1}^W
       \left\{
          \xi_i(b_{j+1}, m_j)\log m_b + 
          \sum_{l=0}^{W-1}\xi_i(m_j,m_{K_{jl}})
          \log \left[m_dF(l, d) + [l=W-1]m \right]
       \right\} \\
                     &= \left(\sum_{i=1}^n\sum_{j=1}^W \xi_i(b_{j+1}, m_j)\right)\log m_b  + \\ 
                     & \quad
		     \sum_{l=0}^{W-1}\left(\sum_{i=1}^n\sum_{j=1}^W\xi_i(m_j,
		     m_{K_{jl}})\right)\log \left[m_d F(l,d) +
		     [l=W-1]m\right]

Since we are going to solve the problem numerically it is possible
that we reach a local maximum. As long as we improve the starting
point it is enough.


